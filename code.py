# -*- coding: utf-8 -*-
"""Venkata Naga Umesh Munagala_Python_Code_Assignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kjdSW9klxYRjrwcTUDCBQucosfmniBLT
"""

# Computer Vision Programming Assignment -II #
                                                          # ''''''''''''''''''''''''''''''''''''''''''''''''#
# Name : Venkata Naga Umesh Munagala
# UCF ID: 5574972

import time
import torch
import torch.nn as nn
import torch.nn.functional as F

class ConvNet(nn.Module):
    def __init__(self, mode, image_size, num_classes):
        super(ConvNet, self).__init__()

        # Define various layers here, such as in the tutorial example
        # self.conv1 = nn.Conv2D(...)
        self.conv1 = nn.Conv2d(
            in_channels=1,
            out_channels=40,
            kernel_size=(5, 5),
            stride=(1, 1),
            padding=(1, 1),
        )
        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 1))
        self.conv2 = nn.Conv2d(
            in_channels=40,
            out_channels=40,
            kernel_size=(5, 5),
            stride=(1, 1),
            padding=(1, 1),
        )

        # This will select the forward pass function based on mode for the ConvNet.
        # Based on the question, you have 5 modes available for step 1 to 5.
        # During creation of each ConvNet model, you will assign one of the valid mode.
        # This will fix the forward function (and the network graph) for the entire training/testing

        if mode == 1:
            self.fc1 = nn.Linear(image_size, 100)
            self.fc2 = nn.Linear(100, num_classes)
            self.forward = self.model_1
        elif mode == 2:
          self.fc1 = nn.Linear(19360, 100)
          self.fc2 = nn.Linear(100, num_classes)
          self.forward = self.model_2
        elif mode == 3:
            self.fc1 = nn.Linear(19360, 100)
            self.fc2 = nn.Linear(100, num_classes)
            self.forward = self.model_3
        elif mode == 4:
            self.fc1 = nn.Linear(23 * 23 * 40, 100)
            self.fc2 = nn.Linear(100, 100)
            self.fc3 = nn.Linear(100, num_classes)
            self.forward = self.model_4
        elif mode == 5:
            self.fc1 = nn.Linear(23 * 23 * 40, 1000)
            self.fc2 = nn.Linear(1000, 1000)
            self.fc3 = nn.Linear(1000, num_classes)
            self.dropout = nn.Dropout(0.5)
            self.forward = self.model_5
        else:
            print("Invalid mode ", mode, "selected. Select between 1-5")
            exit(0)


    # Baseline model. step 1
    def model_1(self, X):
        # ======================================================================
        # One fully connected layer.
	      #STEP 1: Create a fully connected (FC) hidden layer (with 100 neurons) with Sigmoid activation function.
        # Train it with SGD with a learning rate of 0.1 (a total of 60 epoch), a mini-batch size of 10, and no regularization.
        X = X.reshape(X.shape[0], -1)
        X = torch.sigmoid(self.fc1(X))
        X = self.fc2(X)

        return X

    # Use two convolutional layers.
    def model_2(self, X):
        # ======================================================================
        # Two convolutional layers + one fully connnected layer.
        X = torch.sigmoid(self.conv1(X))
        X = self.pool(X)
        X = torch.sigmoid(self.conv2(X))
        X = self.pool(X)
        X = X.reshape(X.shape[0], -1)
        X = torch.sigmoid(self.fc1(X))
        X = self.fc2(X)

        return X

    # Replace sigmoid with ReLU.
    def model_3(self, X):
        # ======================================================================
        # Two convolutional layers + one fully connected layer, with ReLU.
        X = F.relu(self.conv1(X))
        X = self.pool(X)
        X = F.relu(self.conv2(X))
        X = self.pool(X)
        X = X.reshape(X.shape[0], -1)
        X = F.relu(self.fc1(X))
        X = self.fc2(X)

        return X

    # Add one extra fully connected layer.
    def model_4(self, X):
        # ======================================================================
        # Two convolutional layers + two fully connected layers, with ReLU.
        X = F.relu(self.conv1(X))
        X = self.pool(X)
        x = F.relu(self.conv2(X))
        X = self.pool(X)
        X = x.reshape(X.shape[0], -1)
        X = F.relu(self.fc1(X))
        X = F.relu(self.fc2(X))
        X = self.fc3(X)

        return X

    # Use Dropout now.
    def model_5(self, X):
        # ======================================================================
        # Two convolutional layers + two fully connected layers, with ReLU.
        # and  + Dropout.
        X = F.relu(self.conv1(X))
        X = self.pool(X)
        x = F.relu(self.conv2(X))
        X = self.pool(X)
        X = x.reshape(X.shape[0], -1)
        X = F.relu(self.fc1(X))
        X = F.relu(self.fc2(X))
        X = self.dropout(X)
        X = self.fc3(X)

        return X

from __future__ import print_function
import argparse
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torch.utils.tensorboard import SummaryWriter
import argparse
import numpy as np
import matplotlib.pyplot as plt

# Check if cuda is available
use_cuda = torch.cuda.is_available()

# Set proper device based on cuda availability
device = torch.device("cuda" if use_cuda else "cpu")
print("Torch device selected: ", device)

# Create transformations to apply to each data sample
# Can specify variations such as image flip, color flip, random crop, ...
transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])

# Load datasets for training and testing
# Inbuilt datasets available in torchvision (check documentation online)
dataset1 = datasets.MNIST('./data/', train=True, download=True,transform=transform)
dataset2 = datasets.MNIST('./data/', train=False,transform=transform)

def load_data(batch_size=10, num_workers=4):
    train_loader = DataLoader(dataset1, batch_size = batch_size, shuffle=True, num_workers=4)
    test_loader = DataLoader(dataset2, batch_size = batch_size, shuffle=False, num_workers=4)

    return train_loader, test_loader

#For ploting graph and saving it.
def plot(num_epochs, train_losses, train_accuracies, model,best_accuracy):
    x = np.arange(num_epochs)

    plt.plot(x, train_losses) # Plot the training loss over epochs
    plt.plot(x, train_accuracies) # Plot the training accuracy over epochs
    # Adds legend to the plot to distinguish between loss and accuracy, and show the best accuracy achieved for them
    plt.legend(['Train Loss', 'Train Accuracy'],title=f'Accuracy = {best_accuracy: .2f}')
    plt.savefig(f'Model_1.jpg') # Save the plot as an image with a specific filename
    plt.show() # Display the plot

def train(model, device, train_loader, optimizer, criterion, epoch, batch_size, num_epochs):
    '''
    Trains the model for an epoch and optimizes it.
    model: The model to train. Should already be in correct device.
    device: 'cuda' or 'cpu'.
    train_loader: dataloader for training samples.
    optimizer: optimizer to use for model parameter updates.
    criterion: used to compute loss for prediction and target
    epoch: Current epoch to train for.
    batch_size: Batch size to be used.
    '''
    model.train()  # Set the model to training mode (enables gradient computation)
    losses = []  # List to store individual batch losses
    correct = 0  # Counter for correct predictions

    for batch_idx, batch_sample in enumerate(train_loader):
        data, target = batch_sample
        data, target = data.to(device), target.to(device)  # Move data and target to the specified device

        optimizer.zero_grad()  # Reset gradients to zero to avoid gradient accumulation

        output = model(data)  # Forward pass to get model predictions
        loss = criterion(output, target)  # Calculate the loss

        loss.backward()  # Backpropagate the loss to compute gradients

        losses.append(loss.item())  # Append the batch loss to the list

        optimizer.step()  # Update model parameters based on computed gradients

        _, predictions = output.max(1)  # Get the index of the maximum prediction (argmax)
        correct += (predictions == target).sum()  # Count correct predictions in the batch

        # Print progress (batch-wise) - accuracy is shown as it accumulates
        if (batch_idx + 1) * batch_size % 100 == 0:
            print(f'Training epoch: ({epoch+1}/{num_epochs}) batch: ({batch_idx+1}/{len(train_loader)}), ' +
                  f'Accuracy: {correct}/{(batch_idx+1) * batch_size} ({100. * correct / ((batch_idx+1) * batch_size):.0f}%)', end='\r')

    train_loss = float(np.mean(losses))  # Calculate the average training loss for the epoch
    train_acc = correct / ((batch_idx + 1) * batch_size)  # Calculate the training accuracy for the epoch

    # Print the summary of the epoch's training performance
    print(f'\nTrain set ({epoch+1}/{num_epochs}): Average loss: {train_loss:.4f}, ' +
          f'Accuracy: {correct}/{(batch_idx+1) * batch_size} ({100. * correct / ((batch_idx+1) * batch_size):.0f}%)')

    return train_loss, train_acc  # Return training loss and accuracy


def test(model, device, test_loader, criterion, epoch, num_epochs, batch_size):
    '''
    Tests the model.
    model: The model to train. Should already be in correct device.
    device: 'cuda' or 'cpu'.
    test_loader: dataloader for test samples.
    '''
    model.eval()  # Set model to eval mode to notify all layers.
    losses = []  # List to store individual batch losses
    correct = 0  # Counter for correct predictions
    # Set torch.no_grad() to disable gradient computation and backpropagation
    with torch.no_grad():
        for batch_idx, sample in enumerate(test_loader):
            data, target = sample
            data, target = data.to(device), target.to(device)  # Move data and target to the specified device

            output = model(data)  # Forward pass to get model predictions
            loss = criterion(output, target)  # Calculate the loss

            losses.append(loss.item())  # Append the batch loss to the list

            _, predictions = output.max(1)  # Get the index of the maximum prediction (argmax)
            correct += (predictions == target).sum()  # Count correct predictions in the batch

            # Print progress (batch-wise) - for tracking the testing process
            print(f'Testing epoch: ({epoch+1}/{num_epochs}) batch: ({batch_idx+1}/{len(test_loader)})', end='\r')

    test_loss = float(np.mean(losses))  # Calculate the average test loss for the entire test dataset
    accuracy = 100. * correct / len(test_loader.dataset)  # Calculate the test accuracy as a percentage

    # Print the summary of the testing performance
    print(f'\nTest set ({epoch+1}/{num_epochs}): Average loss: {test_loss:.4f}, ' +
          f'Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)')

    return test_loss, accuracy  # Return test loss and accuracy


def execute_model(model=1, learning_rate=0.1, batch_size=10, num_epochs=60):

    while True:
        if model is None:
            model = 1
        if learning_rate is None:
            learning_rate = 0.1
        if batch_size is None:
            batch_size = 10
        if num_epochs is None:
            num_epochs = 60

        # Input size of the model
        image_size = 28 * 28
        # Output size of the model
        num_classes = 10

        # Initialize the model and send to the device
        model = ConvNet(model, image_size, num_classes).to(device)
        # Define the loss function.
        criterion = nn.CrossEntropyLoss()
        # Define the optimizer function.
        optimizer = optim.SGD(model.parameters(), lr=learning_rate)
        # Define data loaders for training and testing
        train_loader, test_loader = load_data(batch_size)

        best_accuracy = 0.0

        train_losses = []  # List to store training losses over epochs
        train_accuracies = []  # List to store training accuracies over epochs

        for epoch in range(0, num_epochs):
            # Compute the accuracy and loss for each epoch
            train_loss, train_accuracy = train(model, device, train_loader, optimizer, criterion, epoch, batch_size, num_epochs)
            test_loss, test_accuracy = test(model, device, test_loader, criterion, epoch, num_epochs, batch_size)

            if test_accuracy > best_accuracy:
                best_accuracy = test_accuracy

            # Saves the train accuracy and train loss for this epoch to plot later
            train_losses.append(train_loss)
            train_accuracies.append(train_accuracy.cpu().numpy())

        plot(num_epochs, train_losses, train_accuracies, model, best_accuracy)

        print("Accuracy is {:2.2f}".format(best_accuracy))

        # Emulating a "do-while" loop - repeat only once
        break

    print("Training and evaluation finished")


def execute():
    for i in range(1, 5):
        batch_size = 10
        num_epochs = 60
        learning_rate = 0.1 if i == 1 else 0.03

        # Set different parameters for model 5
        if i == 5:
            num_epochs = 40

        while True:
            # Execute the training and evaluation loop for the current model configuration
            execute_model(i, learning_rate, batch_size, num_epochs)
            break

        # Display information about the current model configuration
        print(('=' * 10) + f"('Training model {i}')"+('=' * 10))
        print(f"Model {i} two convolutional layers that pool over 2x2 regions, 40 kernels, stride = 1, with a kernel size of 5x5.")
        print('\nlearning_rate = {}\nbatch_size = {}\nnum_epochs = {}\n'.format(learning_rate, batch_size, num_epochs) + '\n\n')

# Call the execute function to start training and evaluation for different model configurations
execute()